# DROP Learning

<p align="center"><img src="https://github.com/lakshmiDRIP/DROP/blob/master/DRIP_Logo.gif?raw=true" width="100"></p>

DROP Learning extracts the Agnostic Learning Bounds under Empirical Loss Minimization Schemes.


## Component Packages

 * [***Bound***](https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/bound)
 DROP Learning Bound Package implements Covering Numbers, Concentration, Lipschitz Bounds.

 * [***Kernel***](https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/kernel)
 DROP Learning Kernel Package implements the Statistical Learning Banach Mercer Kernels.

 * [***Regularization***](https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/regularization)
 DROP Learning Kernel Regularization implements the Statistical Learning Empirical Loss Regularizer.

 * [***R<sup>x</sup> -> R<sup>1</sup>***](https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/rxtor1)
 DROP Learning Kernel Regularization R<sup>x</sup> -> R<sup>1</sup> the Suite of Statistical Learning
 	Empirical Loss Penalizers.

 * [***SVM***](https://github.com/lakshmiDRIP/DROP/tree/master/src/main/java/org/drip/learning/svm)
 DROP Learning SVM implements the Kernel SVM Decision Function Operator.


## References

 * Alon, N., S. Ben-David, N. Cesa Bianchi, and D. Haussler (1997): Scale-sensitive Dimensions, Uniform
 Convergence, and Learnability <i>Journal of Association of Computational Machinery</i> <b>44 (4)</b> 615-631

 * Anthony, M., and P. L. Bartlett (1999): <i>Artificial Neural Network Learning - Theoretical
 Foundations</i> <b>Cambridge University Press</b> Cambridge, UK

 * Ash, R. (1965): <i>Information Theory</i> Inter-science</b> New York

 * Bartlett, P. L., P. Long, and R. C. Williamson (1996): Fat-shattering and the Learnability of Real Valued
 Functions <i>Journal of Computational System Science</i> <b>52 (3)</b> 434-452

 * Boucheron, S., G. Lugosi, and P. Massart (2003): Concentration Inequalities Using the Entropy Method
 <i>Annals of Probability</i> <b>31</b> 1583-1614

 * Carl, B. (1985): Inequalities of the Bernstein-Jackson type and the Degree of Compactness of Operator in
 Banach Spaces <i>Annals of the Fourier Institute</i> <b>35 (3)</b> 79-118

 * Carl, B., and I. Stephani (1990): <i>Entropy, Compactness, and Approximation of Operators</i> <b>Cambridge
 University Press</b> Cambridge UK

 * Gordon, Y., H. Konig, and C. Schutt (1987): Geometric and Probabilistic Estimates of Entropy and
 Approximation Numbers of Operators <i>Journal of Approximation Theory</i> <b>49</b> 219-237

 * Kearns, M. J., R. E. Schapire, and L. M. Sellie (1994): <i>Towards Efficient Agnostic Learning</i> Machine
 Learning <b>17 (2)</b> 115-141

 * Konig, H. (1986): <i>Eigenvalue Distribution of Compact Operators</i> <b>Birkhauser</b> Basel, Switzerland

 * Lee, W. S., P. L. Bartlett, and R. C. Williamson (1998): The Importance of Convexity in Learning with
 Squared Loss <i>IEEE Transactions on Information Theory</i> <b>44</b> 1974-1980

 * Lugosi, G. (2002): Pattern Classification and Learning Theory, in: <i>L. Gyor, editor, Principles of
 Non-parametric Learning</i> <b>Springer</b> Wien 5-62

 * Shawe-Taylor, J., P. L. Bartlett, R. C. Williamson, and M. Anthony (1996): A Framework for Structural Risk
 Minimization, in: <i>Proceedings of the 9th Annual Conference on Computational Learning Theory</i>
 <b>ACM</b> New York 68-76

 * Smola, A. J., A. Elisseff, B. Scholkopf, and R. C. Williamson (2000): Entropy Numbers for Convex
 Combinations and mlps, in: <i>Advances in Large Margin Classifiers, A. Smola, P. Bartlett, B. Scholkopf, and
 D. Schuurmans - editors</i> <b>MIT Press</b> Cambridge, MA

 * Vapnik, V., and A. Chervonenkis (1974): <i>Theory of Pattern Recognition (in Russian)</i> <b>Nauka</b>
 Moscow USSR

 * Vapnik, V. (1995): <i>The Nature of Statistical Learning</i> <b>Springer-Verlag</b> New York

 * Williamson, R. C., A. J. Smola, and B. Scholkopf (2000): Entropy Numbers of Linear Function Classes, in:
 <i>Proceedings of the 13th Annual Conference on Computational Learning Theory</i> <b>ACM</b> New York


## DROP Specifications

 * Main                     => https://lakshmidrip.github.io/DROP/
 * Wiki                     => https://github.com/lakshmiDRIP/DROP/wiki
 * GitHub                   => https://github.com/lakshmiDRIP/DROP
 * Repo Layout Taxonomy     => https://github.com/lakshmiDRIP/DROP/blob/master/Taxonomy.md
 * Javadoc                  => https://lakshmidrip.github.io/DROP/Javadoc/index.html
 * Technical Specifications => https://github.com/lakshmiDRIP/DROP/tree/master/Docs/Internal
 * Release Versions         => https://lakshmidrip.github.io/DROP/version.html
 * Community Credits        => https://lakshmidrip.github.io/DROP/credits.html
 * Issues Catalog           => https://github.com/lakshmiDRIP/DROP/issues
